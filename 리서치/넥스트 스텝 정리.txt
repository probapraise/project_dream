Step 1) 리포지토리 스캐폴딩 + 도메인 경계 그대로 코드로 박기

/domain/world, culture, persona, simulation, validation, report

/infra/llm_client, store, web_api

seed/리포트 스키마를 코드로 먼저 고정(예: Pydantic/TypeScript type)

산출물: “빈 기능”이어도 모듈 경계가 살아있는 프로젝트 뼈대

Step 2) 저장소/Run Log 먼저 구현

“나중에 DB/RAG” 이전에, 지금은 Run 단위 재현성이 핵심입니다.

run_id 기준으로:

입력 seed 저장

중간 산출물(스레드 후보/댓글 라운드/운영 이벤트)

validation 결과

최종 report
를 묶어서 저장

산출물: run_id 하나로 결과 재현/디버깅 가능

Step 3) Orchestrator 파이프라인을 “고정 순서”로 구현 (LLM은 아직 stub 가능)

seed_validate → context_load → thread 후보 → 선정 → 댓글 n회 → 이벤트 → 요약 → report

처음엔 LLM 대신 더미 텍스트로 연결해도 됩니다(파이프라인 완성 우선)

산출물: “끝까지 흐르는” 첫 번째 엔드투엔드

Step 4) LLM 프롬프트 템플릿 분리(단일 초대형 프롬프트 금지)

thread 생성 프롬프트

comment 생성 프롬프트

요약/리포트 프롬프트

validation(특히 lore) 체크 프롬프트(가능하면 JSON 출력)

산출물: 교체 가능한 프롬프트 세트 + 회귀 테스트 가능 상태

Step 5) Validation 3중 체크 MVP 버전부터 붙이기

Safety: 완화/마스킹 + 경고

Similarity: 임베딩 top-k 임계치 기반 재작성

Lore: 체크리스트 기반 위반 탐지 + 수정 재작성

산출물: “안전/유사도/정합성” 때문에 망하는 경로를 초반에 차단

Step 6) 평가 seed 10개 자동 실행(회귀 러너) 만들기

eval 커맨드로 10개 seed를 돌리고,

포맷 누락 0건

커뮤니티 분화

갈등 프레임 2개 이상

운영 개입이 떡밥으로 이어짐

validation 경고 기록
을 체크

산출물: 앞으로의 모든 변경을 안전하게 밀 수 있는 “품질 안전망”